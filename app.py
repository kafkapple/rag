import os
import streamlit as st
from pdf_loader import PDFLoader
from vector_store import VectorStore
from rag_model import RAGModel
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# ì„¤ì •
PDF_FOLDER = os.getenv("PDF_FOLDER", "data/")
FAISS_DB_PATH = os.getenv("FAISS_DB_PATH", "faiss_db/")
LMSTUDIO_API_URL = "http://localhost:1234/v1"
LOCAL_MODEL_PATH = os.getenv("MODEL_PATH", "models/mistral-7b-instruct-v0.2.Q4_K_M.gguf")

# Create necessary directories
os.makedirs(PDF_FOLDER, exist_ok=True)
os.makedirs(FAISS_DB_PATH, exist_ok=True)

# PDF ë¬¸ì„œ ë¡œë”©
pdf_loader = PDFLoader(PDF_FOLDER)
documents = pdf_loader.load_pdfs()

# FAISS ë²¡í„° DB ì„¤ì •
vector_store = VectorStore(FAISS_DB_PATH)
if documents:  # Only create if there are documents
    vector_store.create_vector_store(documents)
vector_store.load_vector_store()

# ëª¨ë¸ ì„ íƒ
model_option = st.sidebar.radio(
    "ğŸ¤– ëª¨ë¸ ì„ íƒ",
    ["LM Studio API", "ë¡œì»¬ ëª¨ë¸"]
)

if model_option == "LM Studio API":
    rag_model = RAGModel(model_type="api", api_url=LMSTUDIO_API_URL)
else:
    rag_model = RAGModel(model_type="local", model_path=LOCAL_MODEL_PATH)

# Streamlit UI
st.title("ğŸ“š RAG QA System - PDF ë¬¸ì„œ ê¸°ë°˜ ê²€ìƒ‰")

query = st.text_input("ğŸ’¡ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")

if query:
    with st.spinner("ğŸ” ë¬¸ì„œ ê²€ìƒ‰ ì¤‘..."):
        retrieved_docs = vector_store.search(query, k=3)
        answer = rag_model.generate_answer(query, retrieved_docs)

    st.write("## ğŸ“ ë‹µë³€:")
    st.write(answer)

    st.write("## ğŸ“„ ì°¸ê³  ë¬¸ì„œ:")
    for doc in retrieved_docs:
        st.write(doc.page_content[:500] + "...")
