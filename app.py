import os
import streamlit as st
from pdf_loader import PDFLoader
from vector_store import VectorStore
from rag_model import RAGModel
from dotenv import load_dotenv
import hydra
from hydra.core.global_hydra import GlobalHydra
from omegaconf import DictConfig, OmegaConf

def get_config():
    """Hydra ì„¤ì •ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        GlobalHydra.instance().clear()
        with hydra.initialize(version_base=None, config_path="config"):
            cfg = hydra.compose(config_name="config")
        return cfg
    except:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ ì„¤ì • ë°˜í™˜
        return OmegaConf.create({
            "model": {
                "lm_studio": {
                    "api_url": "http://172.31.249.207:1234/v1",
                    "max_tokens": 4096,
                    "temperature": 0.7,
                    "repeat_penalty": 1.1,
                    "top_p": 0.9
                },
                "local": {
                    "path": "TheBloke/Llama-2-7B-Chat-GGUF/llama-2-7b-chat.Q4_K_M.gguf",
                    "max_tokens": 8192,
                    "temperature": 0.7,
                    "repeat_penalty": 1.1,
                    "top_p": 0.9
                }
            },
            "vector_store": {
                "chunk_size": 500,
                "chunk_overlap": 50,
                "model_name": "sentence-transformers/all-MiniLM-L6-v2"
            },
            "paths": {
                "pdf_folder": "data/"
            }
        })

def main():
    # Load environment variables
    load_dotenv()
    
    # Hydra ì„¤ì •ì„ ì„¸ì…˜ ìƒíƒœë¡œ ê´€ë¦¬
    if 'config' not in st.session_state:
        st.session_state.config = get_config()
    
    cfg = st.session_state.config

    # Create necessary directories
    os.makedirs(cfg.paths.pdf_folder, exist_ok=True)
    
    # PDF ë¬¸ì„œì™€ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì„¸ì…˜ ìƒíƒœë¡œ ê´€ë¦¬
    if 'documents' not in st.session_state:
        st.write("PDF ë¬¸ì„œ ë¡œë”© ì¤‘...")
        pdf_loader = PDFLoader(cfg.paths.pdf_folder)
        st.session_state.documents = pdf_loader.load_pdfs()
        st.session_state.pdf_loader = pdf_loader  # PDF ë¡œë” ì¸ìŠ¤í„´ìŠ¤ ì €ì¥
    
    if 'vector_store' not in st.session_state:
        vector_store = VectorStore("faiss_db", cfg)  # ì§ì ‘ ê²½ë¡œ ì§€ì •
        if st.session_state.documents:  # Only create if there are documents
            with st.spinner("ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘..."):
                vector_store.create_vector_store(st.session_state.documents)
        with st.spinner("ë²¡í„° ì €ì¥ì†Œ ë¡œë”© ì¤‘..."):
            vector_store.load_vector_store()
        st.session_state.vector_store = vector_store
    
    vector_store = st.session_state.vector_store

    # ëª¨ë¸ ì„ íƒ
    model_option = st.sidebar.radio(
        "ğŸ¤– ëª¨ë¸ ì„ íƒ",
        ["LM Studio API", "ë¡œì»¬ ëª¨ë¸"]
    )

    if model_option == "LM Studio API":
        rag_model = RAGModel(
            model_type="api", 
            api_url=cfg.model.lm_studio.api_url
        )
    else:
        rag_model = RAGModel(
            model_type="local", 
            model_path=cfg.model.local.path
        )

    # Streamlit UI
    st.title("ğŸ“š RAG QA System - PDF ë¬¸ì„œ ê¸°ë°˜ ê²€ìƒ‰")

    query = st.text_input("ğŸ’¡ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")

    if query:
        with st.spinner("ğŸ” ë¬¸ì„œ ê²€ìƒ‰ ì¤‘..."):
            retrieved_docs = vector_store.search(query, k=3)
            answer = rag_model.generate_answer(query, retrieved_docs)

        st.write("## ğŸ“ ë‹µë³€:")
        st.write(answer)

        st.write("## ğŸ“„ ì°¸ê³  ë¬¸ì„œ:")
        
        # ê²€ìƒ‰ëœ ì²­í¬ë“¤ì„ ë¬¸ì„œë³„ë¡œ ê·¸ë£¹í™”
        grouped_docs = {}
        for doc in retrieved_docs:
            # ë¬¸ì„œ ì œëª© ì°¾ê¸°
            for title, document in vector_store.documents.items():
                if doc.page_content in document.chunks:
                    if title not in grouped_docs:
                        grouped_docs[title] = []
                    grouped_docs[title].append(doc.page_content)

        # ë¬¸ì„œë³„ë¡œ í‘œì‹œ
        for title, chunks in grouped_docs.items():
            expander = st.expander(f"ğŸ“‘ {title}")
            with expander:
                st.write("### ë¬¸ì„œ ê°œìš”")
                st.write(vector_store.documents[title].content[:300] + "...")
                
                st.write("### ê´€ë ¨ êµ¬ì ˆ")
                for i, chunk in enumerate(chunks, 1):
                    st.markdown(f"**êµ¬ì ˆ {i}:**")
                    st.write(chunk)
                    st.divider()

    # ì‚¬ì´ë“œë°”ì— ì›ë³¸ í…ìŠ¤íŠ¸ ë³´ê¸° ì˜µì…˜ ì¶”ê°€
    with st.sidebar:
        st.write("## ğŸ“‘ ì›ë³¸ ë¬¸ì„œ ë³´ê¸°")
        for title, _ in st.session_state.documents:
            if st.button(f"ğŸ“„ {title}"):
                saved_text = st.session_state.pdf_loader.get_saved_text(title)
                if saved_text:
                    with st.expander(f"ì›ë³¸ í…ìŠ¤íŠ¸ - {title}", expanded=True):
                        st.text(f"ì¶”ì¶œ ì‹œê°„: {saved_text['extracted_at']}")
                        st.text(f"ì›ë³¸ íŒŒì¼: {saved_text['source_pdf']}")
                        st.markdown("---")
                        st.markdown(saved_text['content'])

if __name__ == "__main__":
    main()
